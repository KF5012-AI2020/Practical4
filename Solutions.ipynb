{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "The goal of these exercises is to challenge you a little bit and make you think. The questions are designed to allow you to have a play around and try a few things before getting to the answer. The solutions are obtainable by writing very similar code to what has been explored in the previous notebooks, but may require an extra step of logic.\n",
    "\n",
    "The solutions will be released after the lecture on Thursday.\n",
    "\n",
    "Let's start with importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. a)** Print the `text_data` variable defined below, but with the word `is` removed from all text blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This the best app ever', 'Why this app so bad?', 'Who the user of this app meant to be?', 'The develop of this app a god']\n"
     ]
    }
   ],
   "source": [
    "text_data = [\n",
    "    \"This is the best app ever\",\n",
    "    \"Why is this app so bad?\",\n",
    "    \"Who is the user of this app meant to be?\",\n",
    "    \"The develop of this app is a god\",\n",
    "]\n",
    "\n",
    "# Write your answer here\n",
    "print([x.replace(\" is\",\"\") for x in text_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. b)** Use a `CountVectorizer` to remove the stop-words from `text_data` and transform `text_data` into document-word count matrix. Load the document-word count matrix into a DataFrame and print the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>bad</th>\n",
       "      <th>best</th>\n",
       "      <th>develop</th>\n",
       "      <th>god</th>\n",
       "      <th>meant</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   app  bad  best  develop  god  meant  user\n",
       "0    1    0     1        0    0      0     0\n",
       "1    1    1     0        0    0      0     0\n",
       "2    1    0     0        0    0      1     1\n",
       "3    1    0     0        1    1      0     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function\n",
    "def create_doc_word_df(sparse_mat, feature_names):\n",
    "    return(pd.DataFrame.sparse.from_spmatrix(sparse_mat, \n",
    "                        columns=feature_names))\n",
    "    \n",
    "# Write your answer here\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "count_vect.fit(text_data)\n",
    "create_doc_word_df(count_vect.transform(text_data), count_vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. c)** Create a text processing pipeline using `CountVectorizer` (with English stop-words removed) and `TfidfTransformer`, then fit the pipeline to `text_data` and print head of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>bad</th>\n",
       "      <th>best</th>\n",
       "      <th>develop</th>\n",
       "      <th>god</th>\n",
       "      <th>meant</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.462637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.462637</td>\n",
       "      <td>0.886548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.346182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663385</td>\n",
       "      <td>0.663385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.346182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663385</td>\n",
       "      <td>0.663385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        app       bad      best   develop       god     meant      user\n",
       "0  0.462637  0.000000  0.886548  0.000000  0.000000  0.000000  0.000000\n",
       "1  0.462637  0.886548  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "2  0.346182  0.000000  0.000000  0.000000  0.000000  0.663385  0.663385\n",
       "3  0.346182  0.000000  0.000000  0.663385  0.663385  0.000000  0.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer here\n",
    "text_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "])\n",
    "text_pipe.fit(text_data);\n",
    "create_doc_word_df(text_pipe.transform(text_data),text_pipe.named_steps['vect'].get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. a)** Load the file `Data/newsgroups_train.json` into a Pandas DataFrame named `df_newsgroup_train` and print the first $10$ rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>\\nDo you have Weitek's address/phone number?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>\\n\\n\\n\\n\\nOf course.  The term must be rigidly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>There were a few people who responded to my re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>I have win 3.0 and downloaded several icons an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>\\n\\n\\nI've had the board for over a year, and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   category                                           document\n",
       "0                 rec.autos  I was wondering if anyone out there could enli...\n",
       "1     comp.sys.mac.hardware  A fair number of brave souls who upgraded thei...\n",
       "2     comp.sys.mac.hardware  well folks, my mac plus finally gave up the gh...\n",
       "3             comp.graphics  \\nDo you have Weitek's address/phone number?  ...\n",
       "4                 sci.space  From article <C5owCB.n3p@world.std.com>, by to...\n",
       "5        talk.politics.guns  \\n\\n\\n\\n\\nOf course.  The term must be rigidly...\n",
       "6                   sci.med  There were a few people who responded to my re...\n",
       "7  comp.sys.ibm.pc.hardware                                                ...\n",
       "8   comp.os.ms-windows.misc  I have win 3.0 and downloaded several icons an...\n",
       "9     comp.sys.mac.hardware  \\n\\n\\nI've had the board for over a year, and ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your answer here\n",
    "with open('Data/newsgroups_train.json','r') as in_file:\n",
    "    df_newsgroup_train = pd.DataFrame(json.load(in_file))\n",
    "    \n",
    "df_newsgroup_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. b)** Using `CountVectorizer` (with English stopwords filtered out), `TfidfTransformer`, and `MultinomialNB` create a text classification pipeline named `text_pipe`, and then fit `text_pipe` to the `df_newsgroup_train` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "text_pipe = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_pipe.fit(df_newsgroup_train.document, df_newsgroup_train.category);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. c, i)** Print the classes that can be output by `text_pipe`. \n",
    "\n",
    "*Hint*: Use the `named_steps` attribute to extract `classes_` from the `clf` step of `text_pipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism' 'comp.graphics' 'comp.os.ms-windows.misc'\n",
      " 'comp.sys.ibm.pc.hardware' 'comp.sys.mac.hardware' 'comp.windows.x'\n",
      " 'misc.forsale' 'rec.autos' 'rec.motorcycles' 'rec.sport.baseball'\n",
      " 'rec.sport.hockey' 'sci.crypt' 'sci.electronics' 'sci.med' 'sci.space'\n",
      " 'soc.religion.christian' 'talk.politics.guns' 'talk.politics.mideast'\n",
      " 'talk.politics.misc' 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "print(text_pipe.named_steps['clf'].classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. c, ii)** Create some text input examples, pass them through the text classification pipeline you just created, and print the outputs. Try to create four example inputs such that the classification pipeline outputs the categories `comp.graphics`, `rec.autos`, `rec.sport.baseball`, and `sci.space`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.graphics' 'rec.autos' 'rec.sport.baseball' 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "x_test = [\n",
    "    \"Render on screen\",\n",
    "    \"What a car!\",\n",
    "    \"Hit the ball out the park\",\n",
    "    \"To the moon!\",\n",
    "]\n",
    "print(text_pipe.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. c, iii)** Try to create an example text input you think should result in a particular category, but the text classification pipeline outputs something unexpected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sci.space']\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "x_test = [\n",
    "    \"This startup is a moon shot\",\n",
    "]\n",
    "print(text_pipe.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. d)** For each category, print out the names of the $10$ features with the largest classification weights.\n",
    "\n",
    "*Hint*: Use the variables `feature_names`, `classifier_weights`, and `classifier_classes` defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "['god', 'people', 'don', 'think', 'atheism', 'religion', 'just', 'say', 'atheists', 'islam']\n",
      "comp.graphics\n",
      "['graphics', 'image', 'thanks', 'files', 'file', 'program', 'know', '3d', 'format', 'looking']\n",
      "comp.os.ms-windows.misc\n",
      "['windows', 'file', 'dos', 'files', 'use', 'drivers', 'driver', 'thanks', 'problem', 'card']\n",
      "comp.sys.ibm.pc.hardware\n",
      "['drive', 'scsi', 'card', 'bus', 'controller', 'ide', 'pc', 'thanks', 'disk', 'monitor']\n",
      "comp.sys.mac.hardware\n",
      "['mac', 'apple', 'drive', 'problem', 'thanks', 'simms', 'quadra', 'does', 'monitor', 'know']\n",
      "comp.windows.x\n",
      "['window', 'motif', 'server', 'widget', 'thanks', 'application', 'use', 'x11r5', 'windows', 'using']\n",
      "misc.forsale\n",
      "['sale', '00', 'offer', 'shipping', 'new', 'condition', 'price', 'sell', 'email', 'asking']\n",
      "rec.autos\n",
      "['car', 'cars', 'like', 'engine', 'just', 'dealer', 'good', 'new', 'ford', 'don']\n",
      "rec.motorcycles\n",
      "['bike', 'dod', 'bikes', 'ride', 'motorcycle', 'like', 'riding', 'helmet', 'just', 'don']\n",
      "rec.sport.baseball\n",
      "['year', 'team', 'baseball', 'game', 'games', 'runs', 'hit', 'pitching', 'players', 'braves']\n",
      "rec.sport.hockey\n",
      "['game', 'team', 'hockey', 'play', 'players', 'season', 'games', 'nhl', 'year', 'league']\n",
      "sci.crypt\n",
      "['key', 'encryption', 'clipper', 'chip', 'government', 'keys', 'nsa', 'escrow', 'use', 'people']\n",
      "sci.electronics\n",
      "['use', 'power', 'circuit', 'like', 'does', 'know', 'used', 'voltage', 'thanks', 'don']\n",
      "sci.med\n",
      "['msg', 'geb', 'gordon', 'pitt', 'chastity', 'n3jxp', 'banks', 'dsl', 'cadre', 'skepticism']\n",
      "sci.space\n",
      "['space', 'nasa', 'orbit', 'launch', 'moon', 'like', 'shuttle', 'earth', 'lunar', 'just']\n",
      "soc.religion.christian\n",
      "['god', 'jesus', 'church', 'christians', 'people', 'bible', 'christ', 'christian', 'faith', 'believe']\n",
      "talk.politics.guns\n",
      "['gun', 'guns', 'people', 'weapons', 'don', 'fbi', 'government', 'firearms', 'law', 'just']\n",
      "talk.politics.mideast\n",
      "['israel', 'israeli', 'jews', 'armenian', 'armenians', 'people', 'turkish', 'arab', 'arabs', 'said']\n",
      "talk.politics.misc\n",
      "['people', 'government', 'don', 'tax', 'think', 'just', 'president', 'clinton', 'state', 'know']\n",
      "talk.religion.misc\n",
      "['god', 'jesus', 'christian', 'people', 'bible', 'christians', 'objective', 'koresh', 'don', 'think']\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "feature_names = text_pipe.named_steps['vect'].get_feature_names()\n",
    "classifier_weights = text_pipe.named_steps['clf'].coef_\n",
    "classifier_classes = text_pipe.named_steps['clf'].classes_\n",
    "\n",
    "# Write your answer here\n",
    "for i, category in enumerate(classifier_classes):\n",
    "    top10 = np.argsort(-classifier_weights[i])[:10]\n",
    "    print(category)\n",
    "    print([feature_names[j] for j in top10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. e)** Re-attempt **2. c, iii)** using some of the words output in **2. d)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. a)** Load the file `Data/newsgroups_test.json` into a Pandas DataFrame named `df_newsgroup_test` and use it to evaluate the performance of `text_pipe` on `df_newsgroup_test`.\n",
    "\n",
    "*Hint*: Use the `score` method of `text_pipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779075942644716\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "with open('Data/newsgroups_test.json','r') as in_file:\n",
    "    df_newsgroup_test = pd.DataFrame(json.load(in_file))\n",
    "    \n",
    "print(text_pipe.score(df_newsgroup_test.document, df_newsgroup_test.category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. b)** Create a text classification pipeline named `text_pipe_wstops` that is the same as `text_pipe` (from **2. b)**), but that does not filter out stop words. Then fit `text_pipe_wstops` to `df_newsgroup_train` and evaluate `text_pipe_wstops` on `df_newsgroup_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6062134891131173\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "text_pipe_wstops = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_pipe_wstops.fit(df_newsgroup_train.document, df_newsgroup_train.category);\n",
    "print(text_pipe_wstops.score(df_newsgroup_test.document, df_newsgroup_test.category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the text classification pipeline perform better with or without stopwords filtered out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. c)** Setup a grid search over the values `[None, 'english']` for the `stop_words` attribute of the `vect` stage in `text_pipe_wstops`, fit the grid search to `df_newsgroup_train` and evaluate on `df_newsgroup_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779075942644716\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "grid_params = {\n",
    "    'vect__stop_words': [None, 'english'],\n",
    "}\n",
    "search = GridSearchCV(text_pipe_wstops, grid_params)\n",
    "search.fit(df_newsgroup_train.document, df_newsgroup_train.category);\n",
    "print(search.score(df_newsgroup_test.document, df_newsgroup_test.category))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you explain what is happening?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
