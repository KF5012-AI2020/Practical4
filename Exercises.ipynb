{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "The goal of these exercises is to challenge you a little bit and make you think. The questions are designed to allow you to have a play around and try a few things before getting to the answer. The solutions are obtainable by writing very similar code to what has been explored in the previous notebooks, but may require an extra step of logic.\n",
    "\n",
    "The solutions will be released after the lecture on Thursday.\n",
    "\n",
    "Let's start with importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. a)** Print the `text_data` variable defined below, but with the word `is` removed from all text blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\n",
    "    \"This is the best app ever\",\n",
    "    \"Why is this app so bad?\",\n",
    "    \"Who is the user of this app meant to be?\",\n",
    "    \"The develop of this app is a god\",\n",
    "]\n",
    "\n",
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. b)** Use a `CountVectorizer` to remove the stop-words from `text_data` and transform `text_data` into document-word count matrix. Load the document-word count matrix into a DataFrame and print the head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def create_doc_word_df(sparse_mat, feature_names):\n",
    "    return(pd.DataFrame.sparse.from_spmatrix(sparse_mat, \n",
    "                        columns=feature_names))\n",
    "    \n",
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. c)** Create a text processing pipeline using `CountVectorizer` (with English stop-words removed) and `TfidfTransformer`, then fit the pipeline to `text_data` and print head of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. a)** Load the file `Data/newsgroups_train.json` into a Pandas DataFrame named `df_newsgroup_train` and print the first $10$ rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. b)** Using `CountVectorizer` (with English stopwords filtered out), `TfidfTransformer`, and `MultinomialNB` create a text classification pipeline named `text_pipe`, and then fit `text_pipe` to the `df_newsgroup_train` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. c, i)** Print the classes that can be output by `text_pipe`. \n",
    "\n",
    "*Hint*: Use the `named_steps` attribute to extract `classes_` from the `clf` step of `text_pipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. c, ii)** Create some text input examples, pass them through the text classification pipeline you just created, and print the outputs. Try to create four example inputs such that the classification pipeline outputs the categories `comp.graphics`, `rec.autos`, `rec.sport.baseball`, and `sci.space`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. c, iii)** Try to create an example text input you think should result in a particular category, but the text classification pipeline outputs something unexpected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. d)** For each category, print out the names of the $10$ features with the largest classification weights.\n",
    "\n",
    "*Hint*: Use the variables `feature_names`, `classifier_weights`, and `classifier_classes` defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer given on purpose\n",
    "feature_names = text_pipe.named_steps['vect'].get_feature_names()\n",
    "classifier_weights = text_pipe.named_steps['clf'].coef_\n",
    "classifier_classes = text_pipe.named_steps['clf'].classes_\n",
    "\n",
    "for i, category in enumerate(classifier_classes):\n",
    "    top10 = np.argsort(-classifier_weights[i])[:10]\n",
    "    print(category)\n",
    "    print([feature_names[j] for j in top10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. e)** Re-attempt **2. c, iii)** using some of the words output in **2. d)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. a)** Load the file `Data/newsgroups_test.json` into a Pandas DataFrame named `df_newsgroup_test` and use it to evaluate the performance of `text_pipe` on `df_newsgroup_test`.\n",
    "\n",
    "*Hint*: Use the `score` method of `text_pipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. b)** Create a text classification pipeline named `text_pipe_wstops` that is the same as `text_pipe` (from **2. b)**), but that does not filter out stop words. Then fit `text_pipe_wstops` to `df_newsgroup_train` and evaluate `text_pipe_wstops` on `df_newsgroup_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the text classification pipeline perform better with or without stopwords filtered out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. c)** Setup a grid search over the values `[None, 'english']` for the `stop_words` attribute of the `vect` stage in `text_pipe_wstops`, fit the grid search to `df_newsgroup_train` and evaluate on `df_newsgroup_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you explain what is happening?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
